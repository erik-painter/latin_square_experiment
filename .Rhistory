setwd("~/Folder/R Storage Folder")
setwd("~/R/Desktop")
d_steps<-read.csv("StepsX.csv")
d_steps<-read.csv("StepsX.csv")
d_steps<-read.csv("StepsX.csv")
d_steps<-read.csv("StepsX.csv")
library(ggplot2)
library(dplyr)
library(broom)
library(stargazer)
library(tidyr)
library(tidyverse)
library(httr)
library(jsonlite)
url <- paste0('http://search.api.worldbank.org/api/v2/wds?format=json&
count=China&
qterm=gdp')
data
response <- GET(url)
data
data <- fromJSON(data)
url <- 'http://search.api.worldbank.org/api/v2/wds?format=json&qterm=China%20GDP'
url <- 'http://search.api.worldbank.org/api/v2/wds?format=json&qterm=China%20GDP'
response <- GET(url)
url <- 'https//search.api.worldbank.org/api/v2/wds?format=json&qterm=China%20GDP'
response <- GET(url)
url <- 'https://search.worldbank.org/api/v2/wds?format=json&display_title=wind%20energy'
url <- 'https://search.worldbank.org/api/v2/wds?format=json&display_title=wind%20energy'
response <- GET(url)
data <- content(response, as='text')
data <- fromJSON(data)
View(data)
View(response)
url <- 'https://search.worldbank.org/api/v2/wds?format=json&display_title=china%20gdp'
response <- GET(url)
data <- content(response, as='text')
data <- fromJSON(data)
View(response)
data
url <- 'https://search.worldbank.org/api/v2/wds?format=json&qterm=china%20gdp'
response <- GET(url)
data <- content(response, as='text')
data <- fromJSON(data)
# Analyze json data
data
names(data)
url <- 'https://search.worldbank.org/api/v2/wds?format=json&qterm=china'
url <- 'https://search.worldbank.org/api/v2/wds?format=json&qterm=china'
response <- GET(url)
data <- content(response, as='text')
data <- fromJSON(data)
# Analyze json data
names(data)
data
getwd()
getwd()
effect <- 'Perception on Price'
causes.gr <- c("Type", "Gender", "Medium", "Age", 'Location')
causes <- vector(mode = "list", length = length(causes.gr))
causes[1] <- list(c("Modern", "Renaissance ", "Post Realism", "Contemporary"))
causes[2] <- list(c("Male", "Female"))
causes[3] <- list(c("Painting", "Sculpture", "Architecture", 'Cinema', 'Literature'))
causes[4] <- list(c("Angle", "Engager", "Brake"))
causes[5] <- list(c("North America", "South America", "Asia", 'Europe', 'Australia', 'Africa'))
ss.ceDiag(effect, causes.gr, causes, sub="Team Practice #0")
library(SixSigma)
getwd()
effect <- 'Perception on Price'
causes.gr <- c("Type", "Gender", "Medium", "Age", 'Location')
causes <- vector(mode = "list", length = length(causes.gr))
causes[1] <- list(c("Modern", "Renaissance ", "Post Realism", "Contemporary"))
causes[2] <- list(c("Male", "Female"))
causes[3] <- list(c("Painting", "Sculpture", "Architecture", 'Cinema', 'Literature'))
causes[4] <- list(c("Angle", "Engager", "Brake"))
causes[5] <- list(c("North America", "South America", "Asia", 'Europe', 'Australia', 'Africa'))
ss.ceDiag(effect, causes.gr, causes, sub="Team Practice #0")
getwd()
gender_levels <- c('Male', 'Female')
style_levels <- c('Modern', 'Abstract', 'Realism', 'Contemporary')
medium_levels <- c('Painting', 'Sculpture', 'Architecture', 'Digital')
reputation_levels <- c('Established', 'Emerging', 'Unknown')
size_levels <- c('Large', 'Medium', 'Small')
# Create all possible combinations
combinations <- expand.grid(Gender = gender_levels,
Style = style_levels,
Medium = medium_levels,
Reputation = reputation_levels,
Size = size_levels)
# Randomly shuffle the rows
combinations <- combinations[sample(nrow(combinations)), ]
# Display the first few assignments
head(combinations, 10)
head(combinations, 30)
gender_levels <- c('Male', 'Female')
style_levels <- c('Modern', 'Abstract', 'Realism', 'Contemporary')
medium_levels <- c('Painting', 'Sculpture', 'Architecture', 'Digital')
reputation_levels <- c('Established', 'Emerging', 'Unknown')
size_levels <- c('Large', 'Medium', 'Small')
# Create all possible combinations
combinations <- expand.grid(Gender = gender_levels,
Style = style_levels,
Medium = medium_levels,
Reputation = reputation_levels,
Size = size_levels)
# Randomly shuffle the rows
# combinations <- combinations[sample(nrow(combinations)), ]
# Display the first few assignments
head(combinations, 30)
?expand.grid
install.packages("tinytex")
tinytex::install_tinytex()
Data <- read.csv('Brain.csv')
install.packages('gridExtra')
setwd('~/Desktop/STA 536/Final Project')
# Libraries
library(ggplot2)
library(readxl)
library(dplyr)
library(car)
# Loading in data
data1 <- read_excel("randomized_data_1.xlsx")
data2 <- read_excel("randomized_data_2.xlsx")
data3 <- read_excel("randomized_data_3.xlsx")
data4 <- read_excel("randomized_data_4.xlsx")
data <- rbind(data1, data2, data3, data4)
# Data cleaning
data$Replicate <- rep(seq(1, 4), each = 9)
data$Duration = as.factor(data$Duration)
data$Intensity = as.factor(data$Intensity)
data$TRT = as.factor(data$TRT)
# ANOVA
lm_model <- lm(data$`Cal. Burned` ~ Duration + Intensity + TRT + Replicate, data = data)
anova(lm_model)
# Analyzing residuals
residuals <- residuals(lm_model)
## Normality
qqplot <- qqnorm(residuals)
qq_plot <- qqline(residuals)
hist(residuals, main = "Histogram of Residuals")
shapiro.test(residuals)
## Common variance
# Scatter plot of residuals vs. fitted values
ggplot(data, aes(x = TRT, y = residuals)) +
geom_point(color = 'blue') +
labs(title = 'Scatter Plot of Residuals by Treatment Level')
leveneTest(residuals ~ TRT, data = data)
## No interaction
fitted_values <- fitted(lm_model)
resid_vs_fitted <- plot(fitted_values, residuals,
xlab = "Fitted Values",
ylab = "Residuals",
main = "Residuals vs Fitted Values")
# Add a horizontal line at y = 0 for reference
abline(h = 0, col = "red", lty = 2)
# Post-Hoc multiple comparison
TukeyHSD(aov(lm_model), 'TRT')
setwd('~/Desktop/STA 536/Final Project')
# Libraries
library(ggplot2)
library(readxl)
library(dplyr)
# Loading in data
data1 <- read_excel("randomized_data_1.xlsx")
data2 <- read_excel("randomized_data_2.xlsx")
data3 <- read_excel("randomized_data_3.xlsx")
data4 <- read_excel("randomized_data_4.xlsx")
data <- rbind(data1, data2, data3, data4)
# Exploratory Data Analysis
by(data$`Cal. Burned`, data$TRT, summary)
hist(data$`Cal. Burned`, main = 'Histogram of Caloric Expenditure',
xlab = 'Cal. Burned', ylab = 'Frequency')
boxplot(data$`Cal. Burned`, main = 'Boxplot of Caloric Expenditure',
ylab = 'Cal. Burned')
# Box plot grouped by treatment
boxplot(data$`Cal. Burned` ~ data$TRT, data = data,
main = "Boxplot of Caloric Expenditure by Treatment",
xlab = "Treatment", ylab = "Caloric Expenditure")
# Histogram grouped by TRT
ggplot(data, aes(x = `Cal. Burned`, fill = TRT)) +
geom_histogram(binwidth = 20, position = "dodge", alpha = 0.7) +
labs(title = "Histogram of Caloric Expenditure by Treatment",
x = "Caloric Expenditure",
y = "Frequency") +
theme_minimal() +
theme(legend.position = "top")
setwd('~/Desktop/STA 536/Final Project')
# Libraries
library(ggplot2)
library(readxl)
library(dplyr)
library(car)
# Loading in data
data1 <- read_excel("randomized_data_1.xlsx")
data2 <- read_excel("randomized_data_2.xlsx")
data3 <- read_excel("randomized_data_3.xlsx")
data4 <- read_excel("randomized_data_4.xlsx")
data <- rbind(data1, data2, data3, data4)
# Data cleaning
data$Replicate <- rep(seq(1, 4), each = 9)
data$Duration = as.factor(data$Duration)
data$Intensity = as.factor(data$Intensity)
data$TRT = as.factor(data$TRT)
# ANOVA
lm_model <- lm(data$`Cal. Burned` ~ Duration + Intensity + TRT + Replicate, data = data)
anova(lm_model)
# Analyzing residuals
residuals <- residuals(lm_model)
## Normality
qqplot <- qqnorm(residuals)
qq_plot <- qqline(residuals)
hist(residuals, main = "Histogram of Residuals")
shapiro.test(residuals)
## Common variance
# Scatter plot of residuals vs. fitted values
ggplot(data, aes(x = TRT, y = residuals)) +
geom_point(color = 'blue') +
labs(title = 'Scatter Plot of Residuals by Treatment Level')
leveneTest(residuals ~ TRT, data = data)
## No interaction
fitted_values <- fitted(lm_model)
resid_vs_fitted <- plot(fitted_values, residuals,
xlab = "Fitted Values",
ylab = "Residuals",
main = "Residuals vs Fitted Values")
# Add a horizontal line at y = 0 for reference
abline(h = 0, col = "red", lty = 2)
# Post-Hoc multiple comparison
TukeyHSD(aov(lm_model), 'TRT')
View(lm_model)
setwd('~/Desktop/STA 536/Final Project')
# Libraries
library(randomizr)
# Creating data frame & Latin Square
intensity_level<- c('Low', 'Medium', 'High',
'Low', 'Medium', 'High',
'Low', 'Medium', 'High')
cardio_duration <- c(rep('10', 3), rep('20', 3), rep('30', 3))
workout_type <- c('A', 'B', 'C',
'B', 'C', 'A',
'C', 'A', 'B')
data <- data.frame(Intesity = intensity_level,
Duration = cardio_duration,
Workout = workout_type)
data
latin_square <- matrix(data$Workout, nrow = 3, ncol = 3, byrow = TRUE) # Latin Square
latin_square
row_numbers <- c(1, 2, 3)
row_random_numbers <- runif(length(row_numbers), min = 0, max = 1)
row_random_numbers
#### THE LATIN SQUARE IS RANDOMIZED!
trt_data
# Column numbers and their associated random numbers
col_numbers <- c(1, 2, 3)
col_random_numbers <- runif(length(col_numbers), min = 0, max = 1)
# Combine row and column random numbers into data frames
row_data <- data.frame(row_numbers, row_random_numbers)
col_data <- data.frame(col_numbers, col_random_numbers)
# Sort rows and columns based on random numbers in descending order
sorted_rows <- row_data[order(-row_data$row_random_numbers), "row_numbers"]
sorted_cols <- col_data[order(-col_data$col_random_numbers), "col_numbers"]
# Reorder the Latin square rows and columns based on sorted row and column numbers
latin_square_reordered <- latin_square[sorted_rows, sorted_cols]
# Print the reordered Latin square
print(latin_square_reordered) # Latin Square used in design
# I must now assign treatments randomly to our letters in the Latin Square
trt_numbers <- c("A", "B", "C")
trt_random_numbers <- runif(length(trt_numbers), min = 0, max = 1)
# Combine row and column random numbers into data frames
trt_data <- data.frame(trt_numbers, trt_random_numbers)
#### THE LATIN SQUARE IS RANDOMIZED!
setwd('~/Desktop/STA 536/Final Project')
# Libraries
library(ggplot2)
library(readxl)
library(dplyr)
library(car)
# Loading in data
data1 <- read_excel("randomized_data_1.xlsx")
data2 <- read_excel("randomized_data_2.xlsx")
data3 <- read_excel("randomized_data_3.xlsx")
data4 <- read_excel("randomized_data_4.xlsx")
data <- rbind(data1, data2, data3, data4)
# Data cleaning
data$Replicate <- rep(seq(1, 4), each = 9)
data$Duration = as.factor(data$Duration)
data$Intensity = as.factor(data$Intensity)
data$TRT = as.factor(data$TRT)
# ANOVA
lm_model <- lm(data$`Cal. Burned` ~ Duration + Intensity + TRT + Replicate, data = data)
anova(lm_model)
# Analyzing residuals
residuals <- residuals(lm_model)
## Normality
qqplot <- qqnorm(residuals)
qq_plot <- qqline(residuals)
hist(residuals, main = "Histogram of Residuals")
shapiro.test(residuals)
## Common variance
# Scatter plot of residuals vs. fitted values
ggplot(data, aes(x = TRT, y = residuals)) +
geom_point(color = 'blue') +
labs(title = 'Scatter Plot of Residuals by Treatment Level')
leveneTest(residuals ~ TRT, data = data)
TukeyHSD(aov(lm_model), 'TRT')
# Exploratory Data Analysis
by(data$`Cal. Burned`, data$TRT, summary)
setwd('~/Desktop/STA 536/Final Project')
# Libraries
library(ggplot2)
library(readxl)
library(dplyr)
library(car)
# Loading in data
data1 <- read_excel("randomized_data_1.xlsx")
data2 <- read_excel("randomized_data_2.xlsx")
data3 <- read_excel("randomized_data_3.xlsx")
data4 <- read_excel("randomized_data_4.xlsx")
data <- rbind(data1, data2, data3, data4)
# Data cleaning
data$Replicate <- rep(seq(1, 4), each = 9)
data$Duration = as.factor(data$Duration)
data$Intensity = as.factor(data$Intensity)
data$TRT = as.factor(data$TRT)
# ANOVA
lm_model <- lm(data$`Cal. Burned` ~ Duration + Intensity + TRT + Replicate, data = data)
anova(lm_model)
# Analyzing residuals
residuals <- residuals(lm_model)
## Normality
qqplot <- qqnorm(residuals)
qq_plot <- qqline(residuals)
hist(residuals, main = "Histogram of Residuals")
shapiro.test(residuals)
## Common variance
# Scatter plot of residuals vs. fitted values
ggplot(data, aes(x = TRT, y = residuals)) +
geom_point(color = 'blue') +
labs(title = 'Scatter Plot of Residuals by Treatment Level')
leveneTest(residuals ~ TRT, data = data)
## No interaction
fitted_values <- fitted(lm_model)
resid_vs_fitted <- plot(fitted_values, residuals,
xlab = "Fitted Values",
ylab = "Residuals",
main = "Residuals vs Fitted Values")
# Add a horizontal line at y = 0 for reference
abline(h = 0, col = "red", lty = 2)
# Post-Hoc multiple comparison
TukeyHSD(aov(lm_model), 'TRT')
setwd('~/Desktop/STA 536/Final Project')
# Libraries
library(ggplot2)
library(readxl)
library(dplyr)
library(car)
# Loading in data
data1 <- read_excel("randomized_data_1.xlsx")
data2 <- read_excel("randomized_data_2.xlsx")
data3 <- read_excel("randomized_data_3.xlsx")
data4 <- read_excel("randomized_data_4.xlsx")
data <- rbind(data1, data2, data3, data4)
# Data cleaning
data$Replicate <- rep(seq(1, 4), each = 9)
data$Duration = as.factor(data$Duration)
data$Intensity = as.factor(data$Intensity)
data$TRT = as.(data$TRT)
data$TRT = as.factor(data$TRT)
data$Replicate = as.factor(data$Replicate)
# ANOVA
lm_model <- lm(data$`Cal. Burned` ~ Duration + Intensity + TRT + Replicate, data = data)
anova(lm_model)
setwd('~/Desktop/STA 536/Final Project')
# Libraries
library(ggplot2)
library(readxl)
library(dplyr)
library(car)
# Loading in data
data1 <- read_excel("randomized_data_1.xlsx")
data2 <- read_excel("randomized_data_2.xlsx")
data3 <- read_excel("randomized_data_3.xlsx")
data4 <- read_excel("randomized_data_4.xlsx")
data <- rbind(data1, data2, data3, data4)
# Data cleaning
data$Replicate <- rep(seq(1, 4), each = 9)
data$Duration = as.factor(data$Duration)
data$Intensity = as.factor(data$Intensity)
data$TRT = as.factor(data$TRT)
data$Replicate = as.factor(data$Replicate)
# ANOVA
lm_model <- lm(data$`Cal. Burned` ~ Duration + Intensity + TRT + Replicate, data = data)
anova(lm_model)
# Analyzing residuals
residuals <- residuals(lm_model)
## Normality
qqplot <- qqnorm(residuals)
qq_plot <- qqline(residuals)
hist(residuals, main = "Histogram of Residuals")
shapiro.test(residuals)
ggplot(data, aes(x = TRT, y = residuals)) +
geom_point(color = 'blue') +
labs(title = 'Scatter Plot of Residuals by Treatment Level')
leveneTest(residuals ~ TRT, data = data)
## No interaction
fitted_values <- fitted(lm_model)
resid_vs_fitted <- plot(fitted_values, residuals,
xlab = "Fitted Values",
ylab = "Residuals",
main = "Residuals vs Fitted Values")
# Add a horizontal line at y = 0 for reference
abline(h = 0, col = "red", lty = 2)
TukeyHSD(aov(lm_model), 'TRT')
setwd('~/Desktop/STA 536/Final Project')
# Libraries
library(ggplot2)
library(readxl)
library(dplyr)
# Loading in data
data1 <- read_excel("randomized_data_1.xlsx")
data2 <- read_excel("randomized_data_2.xlsx")
data3 <- read_excel("randomized_data_3.xlsx")
data4 <- read_excel("randomized_data_4.xlsx")
data <- rbind(data1, data2, data3, data4)
# Exploratory Data Analysis
by(data$`Cal. Burned`, data$TRT, summary)
# Box plot grouped by treatment
boxplot(data$`Cal. Burned` ~ data$TRT, data = data,
main = "Boxplot of Caloric Expenditure by Treatment",
xlab = "Treatment", ylab = "Caloric Expenditure")
